{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daeddcd7",
   "metadata": {},
   "source": [
    "The data was chosen so we could imitate certain parts in the economical markets, like suply and demand. The reason that are 2 variables that are determinants of inflation expectation, 5-year for the medium and 10-year for the long expectancies, MSCI indexes are used as a reflexion of the financial markets and the 10-year treasury is used as a interest rate variable in the model. As for demand the world GDP seems to be one of the best indicators and it wasnt necessary to have a variable for supply, becase the gold annual supply seems to be constant, amounted to some 4,490 tons in 2018 and is projected to amount to 4,533 tons in 2023, a really small change between years.\n",
    "\n",
    "Using the average gold prices for trying to model the gold prices with the different variables. when we test for linearity, using the multiple scatterplot of the dependent variable against the independent variables, it is possible to see a linearity with almost all variables, but the MSCI's variables do not seem  to have as clear of a linearity compared with the others. By Using a scatterplot with the residuals against the dependent variable, we can see that the residuals don't seem to have any especific pattern. The residuals vs the independent values appear to be independent. Using a qqplot we can see that the residuals follow the red line and the normality tests(shapiro-wilk and kolmogorov) show that the standardized residuals are normally distributed, we don't reject the null hypothesis for the shapiro-wilk, so for alpha equal to 0.05 the standardized residuals are normally distributed. The kolmogorov we dont reject the null hypothesis with p-value equal to 0.7506071234246195 so for alpha equal to 0.05 the 2 sampindependent les are drawn from the same continuous distribution. the Anderson-Darling test also indicate a normality in the residuals.\n",
    "\n",
    "    (The observations you apply your tests to (some form of residuals) aren't independent, so the usual statistics don't have the correct distribution. Further, strictly speaking, none of the residuals you consider will be exactly normal, since your data will never be exactly normal. )\n",
    "    \n",
    "    (Even if your data were to be exactly normal, neither the studentized residuals nor the standardized residuals would be exactly normal. Nevertheless it's much more common for people to examine those (say by QQ plots) than the raw residuals.)\n",
    "\n",
    "Linearity:\n",
    "    \n",
    "    Linearity. This means that the mean of the response variable is a linear combination of the parameters (regression coefficients) and the predictor variables. Note that this assumption is much less restrictive than it may at first seem.\n",
    "\n",
    "\n",
    "Homoscedasicity assumptions:\n",
    "\n",
    "    The last assumption of multiple linear regression is homoscedasticity. A scatterplot of residuals versus predicted values is good way to check for homoscedasticity. There should be no clear pattern in the distribution; if there is a cone-shaped pattern (as shown below), the data is heteroscedastic.\n",
    "    \n",
    "    The sixth assumption of linear regression is homoscedasticity. Homoscedasticity in a model means that the error is constant along the values of the dependent variable. The best way for checking homoscedasticity is to make a scatterplot with the residuals against the dependent variable.\n",
    "    \n",
    "Independence: \n",
    "\n",
    "    To test for non-time-series violations of independence, you can look at plots of the residuals versus independent variables or plots of residuals versus row number in situations where the rows have been sorted or grouped in some way that depends (only) on the values of the independent variables.\n",
    "    \n",
    "    \n",
    "Normality:\n",
    "\n",
    "    If the theoretical residuals are not exactly normally distributed, but the sample size is large enough then the Central Limit Theorem says that the usual inference (tests and confidence intervals, but not necessarily prediction intervals) based on the assumption of normality will still be approximately correct.\n",
    "    Also note that the tests of normality are rule out tests, they can tell you that the data is unlikely to have come from a normal distribution. But if the test is not significant that does not mean that the data came from a normal distribution, it could also mean that you just don't have enough power to see the difference. Larger sample sizes give more power to detect the non-normality, but larger samples and the CLT mean that the non-normality is least important. So for small sample sizes the assumption of normality is important but the tests are meaningless, for large sample sizes the tests may be more accurate, but the question of exact normality becomes meaningless.\n",
    "     Statistical theory says its okay just to assume that  and . Once you do that, determining the percentiles of the standard normal curve is straightforward. The p-th percentile value reduces to just a \"Z-score\" (or \"normal score\"). \n",
    "    \n",
    "Shapiro-Wilk test:\n",
    "\n",
    "    The Shapiro–Wilk test tests the null hypothesis that a sample x1, ..., xn came from a normally distributed population. For instance the Shapiro–Wilk test is known not to work well in samples with many identical values.\n",
    "    \n",
    "Kolmogorov-smirnov:\n",
    "    \n",
    "    This is a two-sided test for the null hypothesis that 2 independent samples are drawn from the same continuous distribution. In practice, the statistic requires a relatively large number of data points (in comparison to other goodness of fit criteria such as the Anderson–Darling test statistic) to properly reject the null hypothesis. \n",
    "    \n",
    "    two-sided: The null hypothesis is that the two distributions are identical, F(x)=G(x) for all x; the alternative is that they are not identical.\n",
    "\n",
    "    less: The null hypothesis is that F(x) >= G(x) for all x; the alternative is that F(x) < G(x) for at least one x.\n",
    "\n",
    "    greater: The null hypothesis is that F(x) <= G(x) for all x; the alternative is that F(x) > G(x) for at least one x.\n",
    "    \n",
    "    \n",
    "    Critical values provided are for the following significance levels:\n",
    "\n",
    "Anderson-Darling test:\n",
    "\n",
    "    The Anderson-Darling test tests the null hypothesis that a sample is drawn from a population that follows a particular distribution.\n",
    "    \n",
    "    normal/exponential\n",
    "    15%, 10%, 5%, 2.5%, 1%\n",
    "\n",
    "    logistic\n",
    "    25%, 10%, 5%, 2.5%, 1%, 0.5%\n",
    "\n",
    "    Gumbel\n",
    "    25%, 10%, 5%, 2.5%, 1%\n",
    "\n",
    "    If the returned statistic is larger than these critical values then for the corresponding significance level, the null hypothesis that the data come from the chosen distribution can be rejected. The returned statistic is referred to as ‘A2’ in the references.\n",
    "    \n",
    "Tools for analyzing residuals:\n",
    "\n",
    "    For the basic analysis of residuals you will use the usual descriptive tools and scatterplots (plotting both fitted values and residuals, as well as the dependent and independent variables you have included in your model..\n",
    "\n",
    "        A histogram, dot-plot or stem-and-leaf plot lets you examine residuals: Standard regression assumes that residuals should be normally distributed. Study the shape of the distribution, watch for outliers and other unusual features.\n",
    "        A Q-Q Plot to assess normality of the residuals.\n",
    "        Plot the residuals against the dependent variable to zoom on the distances from the regression line. The picture you see should not show any particular pattern (random cloud). Look for outliers, groups, systematic features etc. to assess the fit in detail.\n",
    "        Plot the residuals against each independent variables to find out, whether a pattern is clearly related to one of the independents.\n",
    "        Plot the residuals against other variables to find out, whether a structure appearing in the residuals might be explained by another variable (a variable that you might want to include into a more complex model.\n",
    "        etc etc.\n",
    "        \n",
    "Leverage:\n",
    "    \n",
    "    In statistics and in particular in regression analysis, leverage is a measure of how far away the independent variable values of an observation are from those of the other observations. Leverage measures how far away the data point is from the mean value. In general 1/n ≤ hi ≤ 1. Where there are k independent variables in the model, the mean value for leverage is (k+1)/n. A rule of thumb (Steven's) is that values 3 times this mean value are considered large.\n",
    "        \n",
    "        \n",
    "Cook's Distance:\n",
    "\n",
    "    A general rule of thumb is that observations with a Cook's D of more than 3 times the mean, μ, is a possible outlier. An alternative interpretation is to investigate any point over 4/n, where n is the number of observations. Other authors suggest that any “large” Di should be investigated.Values of Cook’s distance of 1 or greater are generally viewed as high.\n",
    "    \n",
    "Regression model evaluatioon:\n",
    "\n",
    "   R-square/ Adjusted R-square:\n",
    "      \n",
    "      \n",
    "    R Square measures how much variability in dependent variable can be explained by the model.\n",
    "    R Square is a good measure to determine how well the model fits the dependent variables. However, it does not take into consideration of overfitting problem. If your regression model has many independent variables, because the model is too complicated, it may fit very well to the training data but performs badly for testing data. That is why Adjusted R Square is introduced because it will penalize additional independent variables added to the model and adjust the metric to prevent overfitting issues.\n",
    "    \n",
    "   Mean Square Error(MSE)/Root Mean Square Error(RMSE):\n",
    "    \n",
    "    While R Square is a relative measure of how well the model fits dependent variables, Mean Square Error is an absolute measure of the goodness for the fit.\n",
    "    It gives you an absolute number on how much your predicted results deviate from the actual number. You cannot interpret many insights from one single result but it gives you a real number to compare against other model results and help you select the best regression model.\n",
    "    \n",
    "    The lower the MSE, the better the forecast.\n",
    "    \n",
    "   Mean Absolute Error(MAE):\n",
    "   \n",
    "    Mean Absolute Error(MAE) is similar to Mean Square Error(MSE). However, instead of the sum of square of error in MSE, MAE is taking the sum of the absolute value of error.\n",
    "    Compare to MSE or RMSE, MAE is a more direct representation of sum of error terms. MSE gives larger penalization to big prediction error by square it while MAE treats all errors the same.\n",
    "    \n",
    "   Conclusion:\n",
    "   \n",
    "    R Square/Adjusted R Square is better used to explain the model to other people because you can explain the number as a percentage of the output variability. MSE, RMSE, or MAE are better be used to compare performance between different regression models. Personally, I would prefer using RMSE and I think Kaggle also uses it to assess the submission. However, it makes total sense to use MSE if the value is not too big and MAE if you do not want to penalize large prediction errors.\n",
    "    Adjusted R square is the only metric here that considers the overfitting problem.\n",
    "    \n",
    "    \n",
    "   AIC:\n",
    "   \n",
    "    The Akaike information criterion (AIC) is a mathematical method for evaluating how well a model fits the data it was generated from. In statistics, AIC is used to compare different possible models and determine which one is the best fit for the data. AIC is calculated from:\n",
    "\n",
    "    - number of independent variables used to build the model.\n",
    "    - the maximum likelihood estimate of the model (how well the model reproduces the data).\n",
    "\n",
    "    The best-fit model according to AIC is the one that explains the greatest amount of variation using the fewest possible independent variables.\n",
    "    \n",
    "    Once you’ve created several possible models, you can use AIC to compare them. Lower AIC scores are better, and AIC penalizes models that use more parameters. So if two models explain the same amount of variation, the one with fewer parameters will have a lower AIC score and will be the better-fit model.º\n",
    "    \n",
    "    \n",
    "   F-test:\n",
    "    \n",
    "    The F-test of overall significance indicates whether your linear regression model provides a better fit to the data than a model that contains no independent variables. ... R-squared tells you how well your model fits the data, and the F-test is related to it. An F-test is a type of statistical test that is very flexible.\n",
    "    \n",
    "    \n",
    "    The F-test for overall significance has the following two hypotheses:\n",
    "\n",
    "    - The null hypothesis states that the model with no independent variables fits the data as well as your model.\n",
    "    - The alternative hypothesis says that your model fits the data better than the intercept-only model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
